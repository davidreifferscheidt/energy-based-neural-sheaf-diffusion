{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.decomposition import PCA\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "from cbsd.nn.builders import ConsistencyBasedLaplacianBuilder\n",
    "from cbsd.utils.logging import print_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">name</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">snn                                                                                                          </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">hidden_channels</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">16                                                                                                </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">num_layers</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">32                                                                                                     </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">dropout</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">0.7                                                                                                       </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">input_dropout</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">0                                                                                                   </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">left_weights</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">true                                                                                                 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">right_weights</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">true                                                                                                </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">sheaf_laplacian</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"background-color: #f8f8f8\">                                                                                                   </span>\n",
       "<span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\">  </span><span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">type</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">connection                                                                                                 </span>\n",
       "<span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\">  </span><span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">d</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">2                                                                                                             </span>\n",
       "<span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\">  </span><span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">normalised</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">false                                                                                                </span>\n",
       "<span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\">  </span><span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">deg_normalised</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">true                                                                                             </span>\n",
       "<span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\">  </span><span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">add_lp</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">false                                                                                                    </span>\n",
       "<span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\">  </span><span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">add_hp</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">false                                                                                                    </span>\n",
       "<span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\">  </span><span style=\"color: #008000; text-decoration-color: #008000; background-color: #f8f8f8; font-weight: bold\">augmented</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #f8f8f8\">:</span><span style=\"color: #bbbbbb; text-decoration-color: #bbbbbb; background-color: #f8f8f8\"> </span><span style=\"background-color: #f8f8f8\">true                                                                                                  </span>\n",
       "<span style=\"background-color: #f8f8f8\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;0;128;0;48;2;248;248;248mname\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248msnn                                                                                                          \u001b[0m\n",
       "\u001b[1;38;2;0;128;0;48;2;248;248;248mhidden_channels\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248m16                                                                                                \u001b[0m\n",
       "\u001b[1;38;2;0;128;0;48;2;248;248;248mnum_layers\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248m32                                                                                                     \u001b[0m\n",
       "\u001b[1;38;2;0;128;0;48;2;248;248;248mdropout\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248m0.7                                                                                                       \u001b[0m\n",
       "\u001b[1;38;2;0;128;0;48;2;248;248;248minput_dropout\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248m0                                                                                                   \u001b[0m\n",
       "\u001b[1;38;2;0;128;0;48;2;248;248;248mleft_weights\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248mtrue                                                                                                 \u001b[0m\n",
       "\u001b[1;38;2;0;128;0;48;2;248;248;248mright_weights\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248mtrue                                                                                                \u001b[0m\n",
       "\u001b[1;38;2;0;128;0;48;2;248;248;248msheaf_laplacian\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[48;2;248;248;248m                                                                                                   \u001b[0m\n",
       "\u001b[38;2;187;187;187;48;2;248;248;248m  \u001b[0m\u001b[1;38;2;0;128;0;48;2;248;248;248mtype\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248mconnection                                                                                                 \u001b[0m\n",
       "\u001b[38;2;187;187;187;48;2;248;248;248m  \u001b[0m\u001b[1;38;2;0;128;0;48;2;248;248;248md\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248m2                                                                                                             \u001b[0m\n",
       "\u001b[38;2;187;187;187;48;2;248;248;248m  \u001b[0m\u001b[1;38;2;0;128;0;48;2;248;248;248mnormalised\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248mfalse                                                                                                \u001b[0m\n",
       "\u001b[38;2;187;187;187;48;2;248;248;248m  \u001b[0m\u001b[1;38;2;0;128;0;48;2;248;248;248mdeg_normalised\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248mtrue                                                                                             \u001b[0m\n",
       "\u001b[38;2;187;187;187;48;2;248;248;248m  \u001b[0m\u001b[1;38;2;0;128;0;48;2;248;248;248madd_lp\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248mfalse                                                                                                    \u001b[0m\n",
       "\u001b[38;2;187;187;187;48;2;248;248;248m  \u001b[0m\u001b[1;38;2;0;128;0;48;2;248;248;248madd_hp\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248mfalse                                                                                                    \u001b[0m\n",
       "\u001b[38;2;187;187;187;48;2;248;248;248m  \u001b[0m\u001b[1;38;2;0;128;0;48;2;248;248;248maugmented\u001b[0m\u001b[38;2;0;0;0;48;2;248;248;248m:\u001b[0m\u001b[38;2;187;187;187;48;2;248;248;248m \u001b[0m\u001b[48;2;248;248;248mtrue                                                                                                  \u001b[0m\n",
       "\u001b[48;2;248;248;248m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root = os.path.dirname(os.getcwd())\n",
    "path = os.path.join(root, \"config/model/snn.yaml\")\n",
    "conf = OmegaConf.load(path)\n",
    "print_config(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eba689f0868484c9ad034710264bb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss Total: 474.5012, Loss: 679.1887, Loss Reg: 344.2486\n",
      "Epoch 2/100, Loss Total: 321.7773, Loss: 479.4453, Loss Reg: 308.8946\n",
      "Epoch 3/100, Loss Total: 213.3175, Loss: 335.7481, Loss Reg: 276.4048\n",
      "Epoch 4/100, Loss Total: 139.4621, Loss: 236.1779, Loss Reg: 247.4014\n",
      "Epoch 5/100, Loss Total: 90.4066, Loss: 168.5474, Loss Reg: 222.1562\n",
      "Epoch 6/100, Loss Total: 58.5650, Loss: 123.4483, Loss Reg: 200.9679\n",
      "Epoch 7/100, Loss Total: 38.7057, Loss: 94.4088, Loss Reg: 184.1065\n",
      "Epoch 8/100, Loss Total: 27.1551, Loss: 76.8575, Loss Reg: 171.6542\n",
      "Epoch 9/100, Loss Total: 21.1609, Loss: 67.2934, Loss Reg: 163.3694\n",
      "Epoch 10/100, Loss Total: 18.6177, Loss: 62.9422, Loss Reg: 158.6803\n",
      "Epoch 11/100, Loss Total: 18.0315, Loss: 61.7410, Loss Reg: 156.8061\n",
      "Epoch 12/100, Loss Total: 18.3850, Loss: 62.2091, Loss Reg: 156.9115\n",
      "Epoch 13/100, Loss Total: 18.9517, Loss: 63.2465, Loss Reg: 158.2274\n",
      "Epoch 14/100, Loss Total: 19.1810, Loss: 64.0079, Loss Reg: 160.1263\n",
      "Epoch 15/100, Loss Total: 18.7041, Loss: 63.9202, Loss Reg: 162.1606\n",
      "Epoch 16/100, Loss Total: 17.3702, Loss: 62.7302, Loss Reg: 164.0699\n",
      "Epoch 17/100, Loss Total: 15.2168, Loss: 60.4604, Loss Reg: 165.7575\n",
      "Epoch 18/100, Loss Total: 12.3811, Loss: 57.2882, Loss Reg: 167.2475\n",
      "Epoch 19/100, Loss Total: 9.0341, Loss: 53.4537, Loss Reg: 168.6442\n",
      "Epoch 20/100, Loss Total: 5.3670, Loss: 49.2330, Loss Reg: 170.0973\n",
      "Epoch 21/100, Loss Total: 1.5932, Loss: 44.9347, Loss Reg: 171.7726\n",
      "Epoch 22/100, Loss Total: -2.0759, Loss: 40.8611, Loss Reg: 173.8238\n",
      "Epoch 23/100, Loss Total: -5.4718, Loss: 37.2527, Loss Reg: 176.3696\n",
      "Epoch 24/100, Loss Total: -8.4888, Loss: 34.2589, Loss Reg: 179.4796\n",
      "Epoch 25/100, Loss Total: -11.0755, Loss: 31.9485, Loss Reg: 183.1714\n",
      "Epoch 26/100, Loss Total: -13.2218, Loss: 30.3267, Loss Reg: 187.4160\n",
      "Epoch 27/100, Loss Total: -14.9517, Loss: 29.3468, Loss Reg: 192.1456\n",
      "Epoch 28/100, Loss Total: -16.3190, Loss: 28.9173, Loss Reg: 197.2643\n",
      "Epoch 29/100, Loss Total: -17.3964, Loss: 28.9196, Loss Reg: 202.6600\n",
      "Epoch 30/100, Loss Total: -18.2616, Loss: 29.2271, Loss Reg: 208.2164\n",
      "Epoch 31/100, Loss Total: -18.9885, Loss: 29.7200, Loss Reg: 213.8227\n",
      "Epoch 32/100, Loss Total: -19.6429, Loss: 30.2915, Loss Reg: 219.3806\n",
      "Epoch 33/100, Loss Total: -20.2783, Loss: 30.8544, Loss Reg: 224.8092\n",
      "Epoch 34/100, Loss Total: -20.9313, Loss: 31.3479, Loss Reg: 230.0479\n",
      "Epoch 35/100, Loss Total: -21.6206, Loss: 31.7381, Loss Reg: 235.0555\n",
      "Epoch 36/100, Loss Total: -22.3490, Loss: 32.0160, Loss Reg: 239.8088\n",
      "Epoch 37/100, Loss Total: -23.1080, Loss: 32.1900, Loss Reg: 244.2998\n",
      "Epoch 38/100, Loss Total: -23.8803, Loss: 32.2827, Loss Reg: 248.5324\n",
      "Epoch 39/100, Loss Total: -24.6460, Loss: 32.3222, Loss Reg: 252.5185\n",
      "Epoch 40/100, Loss Total: -25.3865, Loss: 32.3356, Loss Reg: 256.2751\n",
      "Epoch 41/100, Loss Total: -26.0876, Loss: 32.3458, Loss Reg: 259.8214\n",
      "Epoch 42/100, Loss Total: -26.7404, Loss: 32.3688, Loss Reg: 263.1773\n",
      "Epoch 43/100, Loss Total: -27.3403, Loss: 32.4151, Loss Reg: 266.3620\n",
      "Epoch 44/100, Loss Total: -27.8873, Loss: 32.4893, Loss Reg: 269.3934\n",
      "Epoch 45/100, Loss Total: -28.3850, Loss: 32.5907, Loss Reg: 272.2877\n",
      "Epoch 46/100, Loss Total: -28.8408, Loss: 32.7139, Loss Reg: 275.0594\n",
      "Epoch 47/100, Loss Total: -29.2633, Loss: 32.8513, Loss Reg: 277.7215\n",
      "Epoch 48/100, Loss Total: -29.6616, Loss: 32.9944, Loss Reg: 280.2857\n",
      "Epoch 49/100, Loss Total: -30.0434, Loss: 33.1364, Loss Reg: 282.7628\n",
      "Epoch 50/100, Loss Total: -30.4162, Loss: 33.2704, Loss Reg: 285.1624\n",
      "Epoch 51/100, Loss Total: -30.7844, Loss: 33.3929, Loss Reg: 287.4938\n",
      "Epoch 52/100, Loss Total: -31.1512, Loss: 33.5024, Loss Reg: 289.7655\n",
      "Epoch 53/100, Loss Total: -31.5176, Loss: 33.5994, Loss Reg: 291.9854\n",
      "Epoch 54/100, Loss Total: -31.8833, Loss: 33.6861, Loss Reg: 294.1608\n",
      "Epoch 55/100, Loss Total: -32.2467, Loss: 33.7664, Loss Reg: 296.2989\n",
      "Epoch 56/100, Loss Total: -32.6052, Loss: 33.8449, Loss Reg: 298.4055\n",
      "Epoch 57/100, Loss Total: -32.9570, Loss: 33.9253, Loss Reg: 300.4862\n",
      "Epoch 58/100, Loss Total: -33.3004, Loss: 34.0109, Loss Reg: 302.5456\n",
      "Epoch 59/100, Loss Total: -33.6343, Loss: 34.1040, Loss Reg: 304.5874\n",
      "Epoch 60/100, Loss Total: -33.9574, Loss: 34.2069, Loss Reg: 306.6146\n",
      "Epoch 61/100, Loss Total: -34.2705, Loss: 34.3192, Loss Reg: 308.6295\n",
      "Epoch 62/100, Loss Total: -34.5744, Loss: 34.4405, Loss Reg: 310.6339\n",
      "Epoch 63/100, Loss Total: -34.8701, Loss: 34.5696, Loss Reg: 312.6289\n",
      "Epoch 64/100, Loss Total: -35.1592, Loss: 34.7049, Loss Reg: 314.6153\n",
      "Epoch 65/100, Loss Total: -35.4426, Loss: 34.8452, Loss Reg: 316.5937\n",
      "Epoch 66/100, Loss Total: -35.7221, Loss: 34.9884, Loss Reg: 318.5643\n",
      "Epoch 67/100, Loss Total: -35.9985, Loss: 35.1337, Loss Reg: 320.5274\n",
      "Epoch 68/100, Loss Total: -36.2721, Loss: 35.2807, Loss Reg: 322.4831\n",
      "Epoch 69/100, Loss Total: -36.5437, Loss: 35.4283, Loss Reg: 324.4316\n",
      "Epoch 70/100, Loss Total: -36.8127, Loss: 35.5774, Loss Reg: 326.3732\n",
      "Epoch 71/100, Loss Total: -37.0796, Loss: 35.7275, Loss Reg: 328.3080\n",
      "Epoch 72/100, Loss Total: -37.3441, Loss: 35.8789, Loss Reg: 330.2361\n",
      "Epoch 73/100, Loss Total: -37.6058, Loss: 36.0322, Loss Reg: 332.1577\n",
      "Epoch 74/100, Loss Total: -37.8643, Loss: 36.1879, Loss Reg: 334.0729\n",
      "Epoch 75/100, Loss Total: -38.1199, Loss: 36.3455, Loss Reg: 335.9815\n",
      "Epoch 76/100, Loss Total: -38.3724, Loss: 36.5053, Loss Reg: 337.8833\n",
      "Epoch 77/100, Loss Total: -38.6216, Loss: 36.6676, Loss Reg: 339.7782\n",
      "Epoch 78/100, Loss Total: -38.8676, Loss: 36.8320, Loss Reg: 341.6660\n",
      "Epoch 79/100, Loss Total: -39.1112, Loss: 36.9977, Loss Reg: 343.5465\n",
      "Epoch 80/100, Loss Total: -39.3521, Loss: 37.1648, Loss Reg: 345.4195\n",
      "Epoch 81/100, Loss Total: -39.5909, Loss: 37.3326, Loss Reg: 347.2849\n",
      "Epoch 82/100, Loss Total: -39.8278, Loss: 37.5009, Loss Reg: 349.1426\n",
      "Epoch 83/100, Loss Total: -40.0629, Loss: 37.6695, Loss Reg: 350.9925\n",
      "Epoch 84/100, Loss Total: -40.2962, Loss: 37.8383, Loss Reg: 352.8345\n",
      "Epoch 85/100, Loss Total: -40.5275, Loss: 38.0077, Loss Reg: 354.6685\n",
      "Epoch 86/100, Loss Total: -40.7570, Loss: 38.1774, Loss Reg: 356.4944\n",
      "Epoch 87/100, Loss Total: -40.9848, Loss: 38.3471, Loss Reg: 358.3121\n",
      "Epoch 88/100, Loss Total: -41.2105, Loss: 38.5172, Loss Reg: 360.1214\n",
      "Epoch 89/100, Loss Total: -41.4344, Loss: 38.6875, Loss Reg: 361.9221\n",
      "Epoch 90/100, Loss Total: -41.6563, Loss: 38.8581, Loss Reg: 363.7141\n",
      "Epoch 91/100, Loss Total: -41.8763, Loss: 39.0289, Loss Reg: 365.4971\n",
      "Epoch 92/100, Loss Total: -42.0944, Loss: 39.1998, Loss Reg: 367.2709\n",
      "Epoch 93/100, Loss Total: -42.3105, Loss: 39.3707, Loss Reg: 369.0353\n",
      "Epoch 94/100, Loss Total: -42.5249, Loss: 39.5413, Loss Reg: 370.7900\n",
      "Epoch 95/100, Loss Total: -42.7377, Loss: 39.7116, Loss Reg: 372.5349\n",
      "Epoch 96/100, Loss Total: -42.9489, Loss: 39.8813, Loss Reg: 374.2697\n",
      "Epoch 97/100, Loss Total: -43.1586, Loss: 40.0502, Loss Reg: 375.9942\n",
      "Epoch 98/100, Loss Total: -43.3669, Loss: 40.2184, Loss Reg: 377.7084\n",
      "Epoch 99/100, Loss Total: -43.5737, Loss: 40.3858, Loss Reg: 379.4120\n",
      "Epoch 100/100, Loss Total: -43.7791, Loss: 40.5523, Loss Reg: 381.1049\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(\n",
    "    root=\"data/Planetoid\", name=\"pubmed\", transform=T.NormalizeFeatures()\n",
    ")[0]\n",
    "x = dataset.x\n",
    "edge_index = dataset.edge_index\n",
    "num_nodes = edge_index.max().item() + 1\n",
    "num_features = dataset.num_features\n",
    "d = conf.sheaf_laplacian.d\n",
    "\n",
    "# Apply PCA to x\n",
    "pca = PCA(n_components=d * 32)\n",
    "x = pca.fit_transform(x.detach().numpy())\n",
    "x = torch.tensor(x, dtype=torch.float32).reshape(num_nodes, d, -1)\n",
    "\n",
    "builder = ConsistencyBasedLaplacianBuilder(\n",
    "    edge_index=edge_index, d=d, init=\"random\"\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "builder = builder.to(device)\n",
    "\n",
    "builder.train(x, 0.1, 100, log_every=1, reg=\"matrix\", lambda_reg=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(138.5013, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(builder.restriction_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0008,  0.0005],\n",
       "          [-0.0002,  0.0009]],\n",
       "\n",
       "         [[ 0.0006,  0.0029],\n",
       "          [ 0.0004, -0.0011]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0003,  0.0011],\n",
       "          [-0.0024, -0.0001]],\n",
       "\n",
       "         [[ 0.0014, -0.0014],\n",
       "          [-0.0022, -0.0031]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0002,  0.0010],\n",
       "          [-0.0010,  0.0004]],\n",
       "\n",
       "         [[ 0.0039, -0.0007],\n",
       "          [-0.0050, -0.0048]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.0033, -0.0014],\n",
       "          [-0.0005,  0.0005]],\n",
       "\n",
       "         [[-0.0003, -0.0019],\n",
       "          [-0.0005, -0.0003]]],\n",
       "\n",
       "\n",
       "        [[[-0.0002, -0.0009],\n",
       "          [ 0.0005, -0.0026]],\n",
       "\n",
       "         [[-0.0005, -0.0022],\n",
       "          [-0.0003, -0.0014]]],\n",
       "\n",
       "\n",
       "        [[[-0.0010,  0.0019],\n",
       "          [-0.0014, -0.0032]],\n",
       "\n",
       "         [[-0.0005,  0.0040],\n",
       "          [-0.0023, -0.0012]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.restriction_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "torch.Size([20341])\n",
      "torch.Size([21883])\n"
     ]
    }
   ],
   "source": [
    "# check if any of the restriction maps are all zeros\n",
    "print(torch.any(torch.all(builder.restriction_maps == 0, dim=1)))\n",
    "# check if any of the restriction maps are negative\n",
    "print(torch.any(builder.restriction_maps < 0))\n",
    "# print the negative values\n",
    "print(builder.restriction_maps[builder.restriction_maps < 0].shape)\n",
    "# print the positive values\n",
    "print(builder.restriction_maps[builder.restriction_maps > 0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
