# @package _global_
defaults:
  - override /data: actor
  - override /model: mlp
  - override /hydra/launcher: slurm

trainer:
  max_epochs: 3000
  log_every_n_steps: 5
  gradient_clip_val: 0.5

early_stopping: 200

wandb:
  group: mlp_actor

hydra:
  sweep:
    dir: ${store_data_path}/multirun/${hydra.job.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweeper:
    params:
      data.split_idx: range(0,10)
      model.hidden_channels: 32, 64
      model.num_layers: 2, 3, 4
      task.optimizer.lr: 0.01, 0.001
      seed: 3044291017, 29297748, 115944586, 1193614241, 4217974420 #, 1064569471, 814137701, 3768068460, 3450973516, 1787449441, 1254175394, 67056219, 1295471370, 2854307242, 1768874893